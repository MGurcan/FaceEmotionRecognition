{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import required packages\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * np.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 28821 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Preprocess all test images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        '../../Data/images/images/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=32,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Preprocess all train images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "        '../../Data/images/images/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=32,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "# create model structure\n",
    "emotion_model = Sequential()\n",
    "\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/9lp6822x67n5q20pk553klcw0000gn/T/ipykernel_96682/3456820699.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  emotion_model_info = emotion_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 27s 59ms/step - loss: 1.8022 - accuracy: 0.2610 - val_loss: 1.6975 - val_accuracy: 0.3198 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "448/448 [==============================] - 26s 58ms/step - loss: 1.6297 - accuracy: 0.3580 - val_loss: 1.5037 - val_accuracy: 0.4035 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "448/448 [==============================] - 27s 59ms/step - loss: 1.4962 - accuracy: 0.4207 - val_loss: 1.3912 - val_accuracy: 0.4674 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 1.3887 - accuracy: 0.4637 - val_loss: 1.3027 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 1.3287 - accuracy: 0.4918 - val_loss: 1.1780 - val_accuracy: 0.5483 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 1.2795 - accuracy: 0.5083 - val_loss: 1.1627 - val_accuracy: 0.5594 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 1.2379 - accuracy: 0.5250 - val_loss: 1.1744 - val_accuracy: 0.5572 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 1.1973 - accuracy: 0.5474 - val_loss: 1.0928 - val_accuracy: 0.6002 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 1.1815 - accuracy: 0.5491 - val_loss: 1.0611 - val_accuracy: 0.6016 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 1.1589 - accuracy: 0.5588 - val_loss: 1.0025 - val_accuracy: 0.6289 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "448/448 [==============================] - 28s 61ms/step - loss: 1.1338 - accuracy: 0.5714 - val_loss: 1.0204 - val_accuracy: 0.6239 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 1.1073 - accuracy: 0.5814 - val_loss: 0.9893 - val_accuracy: 0.6258 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 1.0815 - accuracy: 0.5901 - val_loss: 0.9547 - val_accuracy: 0.6415 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "448/448 [==============================] - 28s 62ms/step - loss: 1.0747 - accuracy: 0.5927 - val_loss: 0.9406 - val_accuracy: 0.6669 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "448/448 [==============================] - 28s 61ms/step - loss: 1.0595 - accuracy: 0.5985 - val_loss: 0.8731 - val_accuracy: 0.6917 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 1.0335 - accuracy: 0.6113 - val_loss: 0.8592 - val_accuracy: 0.6939 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 1.0179 - accuracy: 0.6136 - val_loss: 0.8560 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 0.9908 - accuracy: 0.6294 - val_loss: 0.8205 - val_accuracy: 0.7179 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 0.9832 - accuracy: 0.6306 - val_loss: 0.8132 - val_accuracy: 0.7179 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 0.9741 - accuracy: 0.6336 - val_loss: 0.8086 - val_accuracy: 0.7268 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 0.9590 - accuracy: 0.6443 - val_loss: 0.7590 - val_accuracy: 0.7506 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "448/448 [==============================] - 27s 59ms/step - loss: 0.9430 - accuracy: 0.6532 - val_loss: 0.7316 - val_accuracy: 0.7542 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "448/448 [==============================] - 26s 59ms/step - loss: 0.9203 - accuracy: 0.6576 - val_loss: 0.7169 - val_accuracy: 0.7453 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "448/448 [==============================] - 26s 59ms/step - loss: 0.9056 - accuracy: 0.6592 - val_loss: 0.7311 - val_accuracy: 0.7640 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 0.9062 - accuracy: 0.6626 - val_loss: 0.7033 - val_accuracy: 0.7740 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 0.8684 - accuracy: 0.6737 - val_loss: 0.6459 - val_accuracy: 0.8013 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 0.8612 - accuracy: 0.6798 - val_loss: 0.6709 - val_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 0.8544 - accuracy: 0.6771 - val_loss: 0.6409 - val_accuracy: 0.8092 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "448/448 [==============================] - 27s 61ms/step - loss: 0.8426 - accuracy: 0.6882 - val_loss: 0.6022 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "448/448 [==============================] - 27s 60ms/step - loss: 0.8326 - accuracy: 0.6925 - val_loss: 0.6078 - val_accuracy: 0.8080 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "#emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "callbacks_list = [LearningRateScheduler(scheduler)]\n",
    "\n",
    "# Train the neural network/model\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64,\n",
    "        callbacks=callbacks_list)\n",
    "\n",
    "# save model structure in jason file\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"emotion_model_30epoch.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save trained model weight in .h5 file\n",
    "emotion_model.save_weights('emotion_model_30epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
